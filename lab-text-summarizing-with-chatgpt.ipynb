{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7gkvh__DyNo"
      },
      "source": [
        "# Text summarizing with ChaptGPT\n",
        "In this lesson, you will summarize text with a focus on specific topics.\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lme18vdn9jDq",
        "outputId": "b61c0b09-7529-4891-8eb2-e4052fe5a919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JdNYL_WURpm",
        "outputId": "4b166ff5-3967-478b-9274-e8215aa782f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QeJovj00DyNp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w7jPzj0hDyNq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "client = openai.Client(api_key=\"-\")\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W12QEHcDDyNq"
      },
      "source": [
        "## Text to summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "egXf5lK-DyNq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prod_review = \"\"\"\n",
        "Got this panda plush toy for my daughter's birthday, \\\n",
        "who loves it and takes it everywhere. It's soft and \\\n",
        "super cute, and its face has a friendly look. It's \\\n",
        "a bit small for what I paid though. I think there \\\n",
        "might be other options that are bigger for the \\\n",
        "same price. It arrived a day earlier than expected, \\\n",
        "so I got to play with it myself before I gave it \\\n",
        "to her.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHCcMiwBDyNr"
      },
      "source": [
        "## Summarize with a word/sentence/character limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84K7K8FyDyNr",
        "outputId": "9af6d7bc-522b-497c-db6e-23b398719561",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The panda plush toy is soft, cute, and loved by my daughter, but it's smaller than expected for the price. It arrived early, allowing me to enjoy it first.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JcvrpqtDyNs"
      },
      "source": [
        "## Summarize with a focus on shipping and delivery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pgG_kj7DyNs",
        "outputId": "d178206c-39a0-4bf5-a673-b82369ba697d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The product arrived a day earlier than expected, enhancing the overall experience for the customer.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site to give feedback to the \\\n",
        "Shipping deparmtment.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words, and focusing on any aspects \\\n",
        "that mention shipping and delivery of the product.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eyS_1LYDyNs"
      },
      "source": [
        "## Summarize with a focus on price and value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-klQkDe1DyNt",
        "outputId": "705abc39-88e7-46bc-a497-9b8397823f57",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The panda plush toy is loved for its softness and cuteness, but perceived as overpriced for its small size compared to larger options available at the same price.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site to give feedback to the \\\n",
        "pricing deparmtment, responsible for determining the \\\n",
        "price of the product.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words, and focusing on any aspects \\\n",
        "that are relevant to the price and perceived value.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDoER1fHDyNt"
      },
      "source": [
        "#### Comment\n",
        "- Summaries include topics that are not related to the topic of focus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dqHtlynDyNt"
      },
      "source": [
        "## Try \"extract\" instead of \"summarize\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij6Uc4ZsDyNt",
        "outputId": "5470abc3-e377-4957-c95d-20f8aa0e6958",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The product arrived a day earlier than expected.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to extract relevant information from \\\n",
        "a product review from an ecommerce site to give \\\n",
        "feedback to the Shipping department.\n",
        "\n",
        "From the review below, delimited by triple quotes \\\n",
        "extract the information relevant to shipping and \\\n",
        "delivery. Limit to 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d0rNi6-DyNu"
      },
      "source": [
        "## Summarize multiple product reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZqGnNa10DyNu",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "review_1 = prod_review\n",
        "\n",
        "# review for a standing lamp\n",
        "review_2 = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one \\\n",
        "had additional storage and not too high of a price \\\n",
        "point. Got it fast - arrived in 2 days. The string \\\n",
        "to the lamp broke during the transit and the company \\\n",
        "happily sent over a new one. Came within a few days \\\n",
        "as well. It was easy to put together. Then I had a \\\n",
        "missing part, so I contacted their support and they \\\n",
        "very quickly got me the missing piece! Seems to me \\\n",
        "to be a great company that cares about their customers \\\n",
        "and products.\n",
        "\"\"\"\n",
        "\n",
        "# review for an electric toothbrush\n",
        "review_3 = \"\"\"\n",
        "My dental hygienist recommended an electric toothbrush, \\\n",
        "which is why I got this. The battery life seems to be \\\n",
        "pretty impressive so far. After initial charging and \\\n",
        "leaving the charger plugged in for the first week to \\\n",
        "condition the battery, I've unplugged the charger and \\\n",
        "been using it for twice daily brushing for the last \\\n",
        "3 weeks all on the same charge. But the toothbrush head \\\n",
        "is too small. I’ve seen baby toothbrushes bigger than \\\n",
        "this one. I wish the head was bigger with different \\\n",
        "length bristles to get between teeth better because \\\n",
        "this one doesn’t.  Overall if you can get this one \\\n",
        "around the $50 mark, it's a good deal. The manufactuer's \\\n",
        "replacements heads are pretty expensive, but you can \\\n",
        "get generic ones that're more reasonably priced. This \\\n",
        "toothbrush makes me feel like I've been to the dentist \\\n",
        "every day. My teeth feel sparkly clean!\n",
        "\"\"\"\n",
        "\n",
        "# review for a blender\n",
        "review_4 = \"\"\"\n",
        "So, they still had the 17 piece system on seasonal \\\n",
        "sale for around $49 in the month of November, about \\\n",
        "half off, but for some reason (call it price gouging) \\\n",
        "around the second week of December the prices all went \\\n",
        "up to about anywhere from between $70-$89 for the same \\\n",
        "system. And the 11 piece system went up around $10 or \\\n",
        "so in price also from the earlier sale price of $29. \\\n",
        "So it looks okay, but if you look at the base, the part \\\n",
        "where the blade locks into place doesn’t look as good \\\n",
        "as in previous editions from a few years ago, but I \\\n",
        "plan to be very gentle with it (example, I crush \\\n",
        "very hard items like beans, ice, rice, etc. in the \\\n",
        "blender first then pulverize them in the serving size \\\n",
        "I want in the blender then switch to the whipping \\\n",
        "blade for a finer flour, and use the cross cutting blade \\\n",
        "first when making smoothies, then use the flat blade \\\n",
        "if I need them finer/less pulpy). Special tip when making \\\n",
        "smoothies, finely cut and freeze the fruits and \\\n",
        "vegetables (if using spinach-lightly stew soften the \\\n",
        "spinach then freeze until ready for use-and if making \\\n",
        "sorbet, use a small to medium sized food processor) \\\n",
        "that you plan to use that way you can avoid adding so \\\n",
        "much ice if at all-when making your smoothie. \\\n",
        "After about a year, the motor was making a funny noise. \\\n",
        "I called customer service but the warranty expired \\\n",
        "already, so I had to buy another one. FYI: The overall \\\n",
        "quality has gone done in these types of products, so \\\n",
        "they are kind of counting on brand recognition and \\\n",
        "consumer loyalty to maintain sales. Got it in about \\\n",
        "two days.\n",
        "\"\"\"\n",
        "\n",
        "reviews = [review_1, review_2, review_3, review_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAtDbHL5DyNu",
        "outputId": "5eb41c21-6e84-464c-f30d-4c662c14d5f9",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Cute and soft panda plush toy, but a bit small for the price; arrived early. \n",
            "\n",
            "1 Great lamp with storage, quick delivery, responsive support for issues, and easy assembly. Highly recommended! \n",
            "\n",
            "2 Impressive battery life, but toothbrush head is too small; overall, a good deal if priced around $50. \n",
            "\n",
            "3 Prices increased significantly after a sale; quality seems lower, and motor issues arose after a year. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(reviews)):\n",
        "    prompt = f\"\"\"\n",
        "    Your task is to generate a short summary of a product \\\n",
        "    review from an ecommerce site.\n",
        "\n",
        "    Summarize the review below, delimited by triple \\\n",
        "    backticks in at most 20 words.\n",
        "\n",
        "    Review: ```{reviews[i]}```\n",
        "    \"\"\"\n",
        "\n",
        "    response = get_completion(prompt)\n",
        "    print(i, response, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvip1YrBDyNv"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWSsekskWFXI"
      },
      "source": [
        "# My prompts 1: Art History prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqknXtJZDyNv",
        "outputId": "bfa1c1a5-3299-4fc0-ae54-5dce380a897c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Renaissance art period saw a revival of classical styles and techniques, with significant pieces like Leonardo da Vinci's \"Mona Lisa\" and Michelangelo's \"David\" influencing art worldwide.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of the history of\n",
        "rennaissance art, bring forward the most significant pieces.\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words, and focusing on any aspects \\\n",
        "that are relevant to the topic and how it affected the world.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHs4_PjaWZkx"
      },
      "source": [
        "# My prompts 2: The history of machine learning transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NMMrFd23XYJq"
      },
      "outputs": [],
      "source": [
        "history_1 = \"\"\"\n",
        "For many years, sequence modelling and generation was done by using plain recurrent neural networks (RNNs).\n",
        "A well-cited early example was the Elman network (1990). In theory, the information from one token can propagate arbitrarily far down the sequence,\n",
        "but in practice the vanishing-gradient problem leaves the model's state at the end of a long sentence without precise, extractable information about preceding tokens.\n",
        "\n",
        "A key breakthrough was LSTM (1995),[note 1] a RNN which used various innovations to overcome the vanishing gradient problem,\n",
        "allowing efficient learning of long-sequence modelling. One key innovation was the use of an attention mechanism which used\n",
        " neurons that multiply the outputs of other neurons, so-called multiplicative units.[13] Neural networks using multiplicative units were\n",
        "  later called sigma-pi networks[14] or higher-order networks.[15] LSTM became the standard architecture for long sequence modelling until the\n",
        "  2017 publication of Transformers. However, LSTM still used sequential processing, like most other RNNs.[note 2] Specifically,\n",
        "  RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\n",
        "\n",
        "Modern Transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window.\n",
        "The linearly scaling fast weight controller (1992) learns to compute a weight matrix for further processing depending on the input.[16]\n",
        "One of its two networks has \"fast weights\" or \"dynamic links\" (1981).[17][18][19] A slow neural network learns by gradient descent to generate keys\n",
        "and values for computing the weight changes of the fast neural network which computes answers to queries.[16] This was later shown to be equivalent\n",
        "to the unnormalized linear Transformer.[20][21]\n",
        "\"\"\"\n",
        "\n",
        "history_2 = \"\"\" The idea of encoder-decoder sequence transduction had been developed in the early 2010s (see previous papers[22][23]).\n",
        "The papers most commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.[22][23]\n",
        "\n",
        "A 380M-parameter model for machine translation uses two long short-term memories (LSTM).[23] Its architecture consists of two parts.\n",
        "The encoder is an LSTM that takes in a sequence of tokens and turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of tokens. Similarly,\n",
        "another 130M-parameter model used gated recurrent units (GRU) instead of LSTM.[22] Later research showed that GRUs are neither better nor worse than LSTMs for seq2seq.[24][25]\n",
        "\n",
        "These early seq2seq models had no attention mechanism, and the state vector is accessible only after the last word of the source text was processed.\n",
        "Although in theory such a vector retains the information about the whole original sentence, in practice the information is poorly preserved.\n",
        "This is because the input is processed sequentially by one recurrent network into a fixed-size output vector, which is then processed by another recurrent network into an output.\n",
        "If the input is long, then the output vector would not be able to contain all relevant information, degrading the output. As evidence, reversing the input sentence improved seq2seq translation.[26]\n",
        "\n",
        "The RNNsearch model introduced an attention mechanism to seq2seq for machine translation to solve the bottleneck problem (of the fixed-size output vector),\n",
        "allowing the model to process long-distance dependencies more easily. The name is because it \"emulates searching through a source sentence during decoding a translation\".[4]\n",
        "\n",
        "The relative performances were compared between global (that of RNNsearch) and local (sliding window) attention model architectures for machine translation,\n",
        " finding that mixed attention had higher quality than global attention, while local attention reduced translation time.[27]\n",
        "\n",
        "In 2016, Google Translate was revamped to Google Neural Machine Translation, which replaced the previous model based on statistical machine translation.\n",
        "The new model was a seq2seq model where the encoder and the decoder were both 8 layers of bidirectional LSTM.[28]\n",
        "It took nine months to develop, and it outperformed the statistical approach, which took ten years to develop.[29]\n",
        "\"\"\"\n",
        "history = [history_1, history_2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yn7pvEA-vvz",
        "outputId": "819a3c6e-0096-43b2-9cde-60e269c57223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Transformers revolutionized sequence modeling in 2017, overcoming RNN limitations like sequential processing and vanishing gradients. \n",
            "\n",
            "1 Transformers evolved from early seq2seq models, introducing attention mechanisms for improved machine translation efficiency and performance. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(history)):\n",
        "    prompt = f\"\"\"\n",
        "    Your task is to generate a short summary of the history of transformers \\\n",
        "    review from a history site.\n",
        "\n",
        "    Summarize below, delimited by triple \\\n",
        "    backticks in at most 20 words.\n",
        "\n",
        "    Review: ```{history[i]}```\n",
        "    \"\"\"\n",
        "\n",
        "    response = get_completion(prompt)\n",
        "    print(i, response, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
